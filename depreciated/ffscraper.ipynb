{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_box_scores(start_year, end_year):\n",
    "    box_scores = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        url = f\"https://www.pro-football-reference.com/years/{year}/games.htm\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all box score links for the given year\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            if '/boxscores/' in link['href'] and 'htm' in link['href']:\n",
    "                game_url = f\"https://www.pro-football-reference.com{link['href']}\"\n",
    "                game_date = link.find_previous('th').text.strip() if link.find_previous('th') else \"Unknown Date\"\n",
    "                box_scores.append((game_url, game_date))\n",
    "    return box_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_game_details(game_url):\n",
    "    response = requests.get(game_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Collect home and away team information\n",
    "    game_data = {\n",
    "        'home_team': None,\n",
    "        'away_team': None,\n",
    "        'home_snap_counts': [],\n",
    "        'away_snap_counts': [],\n",
    "        'home_receiving_stats': [],\n",
    "        'away_receiving_stats': [],\n",
    "        'home_rushing_stats': [],\n",
    "        'away_rushing_stats': [],\n",
    "        'home_passing_stats': [],\n",
    "        'away_passing_stats': []\n",
    "    }\n",
    "\n",
    "    # Find team names\n",
    "    team_names = soup.find_all('strong')\n",
    "    if len(team_names) >= 2:\n",
    "        game_data['away_team'] = team_names[0].text.strip()\n",
    "        game_data['home_team'] = team_names[1].text.strip()\n",
    "\n",
    "    # Find snap counts\n",
    "    home_snap_count_table = soup.find('table', {'id': 'home_snap_counts'})\n",
    "    away_snap_count_table = soup.find('table', {'id': 'away_snap_counts'})\n",
    "    if home_snap_count_table:\n",
    "        rows = home_snap_count_table.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) > 0:\n",
    "                team = cells[1].text.strip()\n",
    "                player = cells[0].text.strip()\n",
    "                snaps = cells[2].text.strip()\n",
    "                if team == game_data['home_team']:\n",
    "                    game_data['home_snap_counts'].append((player, snaps))\n",
    "                else:\n",
    "                    game_data['away_snap_counts'].append((player, snaps))\n",
    "\n",
    "    # Find passing, rushing, and receiving stats\n",
    "    stats_tables = {'passing': 'passing', 'rushing': 'rushing', 'receiving': 'receiving'}\n",
    "    for stat_type, table_id in stats_tables.items():\n",
    "        table = soup.find('table', {'id': table_id})\n",
    "        if table:\n",
    "            rows = table.find_all('tr')[1:]\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) > 0:\n",
    "                    player = row.find('th').text.strip()\n",
    "                    team = cells[0].text.strip()\n",
    "                    stats = [cell.text.strip() for cell in cells[1:]]\n",
    "                    if team == game_data['home_team']:\n",
    "                        game_data[f'home_{stat_type}_stats'].append((player, stats))\n",
    "                    else:\n",
    "                        game_data[f'away_{stat_type}_stats'].append((player, stats))\n",
    "\n",
    "    return game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_box_scores(2023,2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = scrape_game_details(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Detroit Lions',\n",
       " 'away_team': 'Detroit Lions at Kansas City Chiefs - September 7th, 2023',\n",
       " 'home_snap_counts': [],\n",
       " 'away_snap_counts': [],\n",
       " 'home_receiving_stats': [],\n",
       " 'away_receiving_stats': [],\n",
       " 'home_rushing_stats': [],\n",
       " 'away_rushing_stats': [],\n",
       " 'home_passing_stats': [],\n",
       " 'away_passing_stats': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Player', 'Team', 'Age', ...])  # Use appropriate column names\n",
    "\n",
    "# Save to a CSV or database\n",
    "df.to_csv('nfl_player_stats.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
