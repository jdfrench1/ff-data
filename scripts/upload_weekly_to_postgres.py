from __future__ import annotations

from _bootstrap import activate

activate()

import argparse
import logging
import os
from pathlib import Path

import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.engine import URL

try:
    from dotenv import load_dotenv
except ImportError:  # pragma: no cover
    load_dotenv = None

logger = logging.getLogger(__name__)

LOG_FORMAT = "%(asctime)s %(levelname)s %(name)s - %(message)s"

MAX_QUERY_PARAMS = 65535


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Upload weekly stats CSV into Postgres",
    )
    parser.add_argument(
        "--csv-path",
        default="nfl_weekly_stats.csv",
        help="Path to CSV generated by the loader",
    )
    parser.add_argument(
        "--table",
        default="nfl_weekly_stats",
        help="Target table name",
    )
    parser.add_argument(
        "--if-exists",
        dest="if_exists",
        default="append",
        choices=["append", "replace", "fail"],
        help="Behavior if the table exists",
    )
    parser.add_argument(
        "--chunk-size",
        dest="chunk_size",
        type=int,
        default=1000,
        help="Rows per batch for to_sql",
    )
    parser.add_argument(
        "--env-file",
        help="Optional path to .env file (defaults to repo .env if present)",
    )
    parser.add_argument(
        "--log-file",
        dest="log_file",
        help="Write log output to the given file (appends)",
    )
    parser.add_argument(
        "--log-level",
        dest="log_level",
        default="INFO",
        choices=["CRITICAL", "ERROR", "WARNING", "INFO", "DEBUG"],
        help="Minimum log level for file/console output (default: INFO)",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help=(
            "Only emit warnings/errors to the console "
            "(full log still goes to file if set)"
        ),
    )
    return parser.parse_args()


def configure_logging(log_level: str, log_file: str | None, quiet: bool) -> None:
    level = getattr(logging, log_level.upper(), logging.INFO)
    root = logging.getLogger()
    root.handlers.clear()
    root.setLevel(level)
    formatter = logging.Formatter(LOG_FORMAT)

    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.WARNING if quiet else level)
    console_handler.setFormatter(formatter)
    root.addHandler(console_handler)

    if log_file:
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        root.addHandler(file_handler)


def load_env(env_file: str | None) -> None:
    if load_dotenv is None:
        return

    if env_file:
        load_dotenv(env_file)
        return

    default_env = Path(".env")
    if default_env.exists():
        load_dotenv(default_env)


def get_required(name: str) -> str:
    value = os.getenv(name)
    if not value:
        raise RuntimeError(
            f"Environment variable {name} is required for database upload",
        )
    return value


def choose_driver() -> str:
    try:
        import psycopg  # noqa: F401

        return "psycopg"
    except ImportError:
        try:
            import psycopg2  # noqa: F401

            return "psycopg2"
        except ImportError as exc:  # pragma: no cover
            raise RuntimeError(
                "Neither psycopg nor psycopg2 drivers are installed.",
            ) from exc


def resolve_chunk_size(requested: int, column_count: int) -> int:
    if requested <= 0:
        raise ValueError("chunk size must be a positive integer")
    if column_count <= 0:
        return requested
    max_rows = max(1, MAX_QUERY_PARAMS // column_count)
    effective = min(requested, max_rows)
    if effective < requested:
        logger.warning(
            "Reducing chunk size from %s to %s to stay under Postgres parameter limit (%s)",
            requested,
            effective,
            MAX_QUERY_PARAMS,
        )
    return effective


def make_engine(
    user: str,
    password: str,
    host: str,
    port: str,
    database: str,
    driver: str,
):
    url = URL.create(
        drivername=f"postgresql+{driver}",
        username=user,
        password=password,
        host=host,
        port=int(port),
        database=database,
    )
    safe_url = url.set(password="***")
    logger.debug("Connecting with URL %s", safe_url)
    return create_engine(url)


def main() -> int:
    args = parse_args()
    configure_logging(args.log_level, args.log_file, args.quiet)

    try:
        load_env(args.env_file)

        csv_path = Path(args.csv_path)
        if not csv_path.exists():
            logger.error("CSV not found at %s", csv_path)
            return 1

        host = get_required("PGHOST")
        port = os.getenv("PGPORT", "5432")
        user = get_required("PGUSER")
        password = get_required("PGPASSWORD")
        database = get_required("PGDATABASE")

        driver = choose_driver()
        engine = make_engine(user, password, host, port, database, driver)

        df = pd.read_csv(csv_path)
        if df.empty:
            logger.warning("CSV contains no rows; skipping upload")
            return 0

        column_count = len(df.columns)
        try:
            chunk_size = resolve_chunk_size(args.chunk_size, column_count)
        except ValueError as exc:
            logger.error(str(exc))
            return 1

        logger.debug("Using chunk size %s for %s columns", chunk_size, column_count)

        logger.info(
            "Uploading %s rows from %s to table %s",
            len(df),
            csv_path,
            args.table,
        )
        df.to_sql(
            args.table,
            engine,
            if_exists=args.if_exists,
            index=False,
            method="multi",
            chunksize=chunk_size,
        )
    except Exception:
        logger.exception("Weekly Postgres upload failed")
        return 1

    logger.info("Uploaded %s rows to %s", len(df), args.table)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
