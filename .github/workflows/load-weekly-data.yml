name: Load Weekly NFL Data

on:
  workflow_dispatch:
    inputs:
      season:
        description: "Season year (e.g., 2024)"
        required: false
        default: "2024"
      week:
        description: "Week number (leave blank for all)"
        required: false
        default: ""
      allow_empty:
        description: "Succeed with empty CSV if data not yet published"
        required: false
        type: boolean
        default: false
  schedule:
    - cron: '0 10 * * TUE'

jobs:
  load:
    runs-on: ubuntu-latest
    env:
      # Expose DB secrets as env so we can reference them in `if:` expressions
      PGHOST: ${{ secrets.PGHOST }}
      PGPORT: ${{ secrets.PGPORT }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt

      - name: Run weekly loader (nflreadpy/nfl_data_py)
        shell: bash
        run: |
          ARGS=( )
          if [ -n "${{ inputs.season }}" ]; then ARGS+=(--season "${{ inputs.season }}"); fi
          if [ -n "${{ inputs.week }}" ]; then ARGS+=(--week "${{ inputs.week }}"); fi
          # Auto-allow empty results on scheduled runs, or if user requested it
          if [ "${{ github.event_name }}" = "schedule" ] || [ "${{ inputs.allow_empty }}" = "true" ]; then
            ARGS+=(--allow-empty)
          fi
          python scripts/load_weekly_data.py "${ARGS[@]}" --output nfl_weekly_stats.csv

      - name: Upload CSV artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: nfl-weekly-stats
          path: nfl_weekly_stats.csv

      - name: Load CSV into Postgres (optional)
        if: ${{ success() && env.PGHOST && env.PGUSER && env.PGDATABASE }}
        run: |
          python - << 'PY'
          import os, sys
          import pandas as pd
          from sqlalchemy import create_engine

          csv_path = 'nfl_weekly_stats.csv'
          if not os.path.exists(csv_path):
              print(f"CSV not found: {csv_path}")
              sys.exit(1)

          user = os.environ['PGUSER']
          pwd = os.environ['PGPASSWORD']
          host = os.environ['PGHOST']
          port = os.environ.get('PGPORT', '5432')
          db = os.environ['PGDATABASE']

          url = f"postgresql+psycopg2://{user}:{pwd}@{host}:{port}/{db}"
          engine = create_engine(url)

          df = pd.read_csv(csv_path)
          # Replace 'nfl_weekly_stats' with your target table if different
          df.to_sql('nfl_weekly_stats', engine, if_exists='append', index=False)
          print('Loaded CSV into Postgres table nfl_weekly_stats')
          PY
