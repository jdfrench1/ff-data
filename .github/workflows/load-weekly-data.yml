name: Load Weekly NFL Data

on:
  workflow_dispatch:
    inputs:
      season:
        description: "Season year (e.g., 2024)"
        required: false
        default: "2024"
      week:
        description: "Week number (leave blank for all)"
        required: false
        default: ""
      allow_empty:
        description: "Succeed with empty CSV if data not yet published"
        required: false
        type: boolean
        default: false
  schedule:
    - cron: '0 10 * * TUE'

jobs:
  load:
    runs-on: [self-hosted, windows, local]
    env:
      # Expose DB secrets as env so we can reference them in `if:` expressions
      PGHOST: ${{ secrets.PGHOST }}
      PGPORT: ${{ secrets.PGPORT }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Check data library availability
        run: |
          python -V
          python - << 'PY'
          import importlib, sys
          for mod in ("nflreadpy","nfl_data_py"):
              try:
                  m = importlib.import_module(mod)
                  ver = getattr(m, "__version__", "(no __version__)")
                  print(f"{mod} version: {ver}")
              except Exception as e:
                  print(f"{mod} not importable: {e}")
          PY

      - name: Run weekly loader
        shell: bash
        run: |
          ARGS=( )
          if [ -n "${{ inputs.season }}" ]; then ARGS+=(--season "${{ inputs.season }}"); fi
          if [ -n "${{ inputs.week }}" ]; then ARGS+=(--week "${{ inputs.week }}"); fi
          # Auto-allow empty results on scheduled runs, or if user requested it
          if [ "${{ github.event_name }}" = "schedule" ] || [ "${{ inputs.allow_empty }}" = "true" ]; then
            ARGS+=(--allow-empty)
          fi
          # Enable verbose diagnostics in logs
          ARGS+=(--verbose)
          python scripts/load_weekly_data.py "${ARGS[@]}" --output nfl_weekly_stats.csv

      - name: Upload CSV artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: nfl-weekly-stats
          path: nfl_weekly_stats.csv

      - name: Load CSV into Postgres (optional)
        if: ${{ success() && env.PGHOST && env.PGUSER && env.PGDATABASE }}
        run: |
          python - << 'PY'
          import os, sys
          import pandas as pd
          from sqlalchemy import create_engine

          csv_path = 'nfl_weekly_stats.csv'
          if not os.path.exists(csv_path):
              print(f"CSV not found: {csv_path}")
              sys.exit(1)

          user = os.environ['PGUSER']
          pwd = os.environ['PGPASSWORD']
          host = os.environ['PGHOST']
          port = os.environ.get('PGPORT', '5432')
          db = os.environ['PGDATABASE']

          # Use psycopg (v3) driver; falls back to psycopg2 if needed
          try:
              import psycopg  # noqa: F401
              driver = "psycopg"
          except ImportError:
              driver = "psycopg2"

          url = f"postgresql+{driver}://{user}:{pwd}@{host}:{port}/{db}"
          engine = create_engine(url)

          df = pd.read_csv(csv_path)
          # Replace 'nfl_weekly_stats' with your target table if different
          df.to_sql('nfl_weekly_stats', engine, if_exists='append', index=False)
          print('Loaded CSV into Postgres table nfl_weekly_stats')
          PY
